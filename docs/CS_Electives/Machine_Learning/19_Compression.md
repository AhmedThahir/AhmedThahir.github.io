# Model Compression

|              |                                                              |
| ------------ | ------------------------------------------------------------ |
| Quantization | Reducing precision from Float64 to Int8                      |
| Pruning      | Removing unnecessary aspects of the model<br />Removing neurons in ANN |
